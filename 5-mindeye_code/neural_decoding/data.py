import os
import re
import glob
import random
import pandas as pd
import numpy as np

import torch
from torch.utils.data import Dataset, DataLoader
from torch.utils.data import ConcatDataset
from torch import nn
from torch.utils.data.distributed import DistributedSampler
import torch.nn.functional as F
from torchvision import transforms

from PIL import Image
import nibabel as nib

import utils

class TrainDataset(Dataset): # ses단위로 실행
    def __init__(self, fmri_path, tsv_path, image_path, mask_path, transform, train=1):
        self.fmri_path = fmri_path
        self.tsv_path = tsv_path
        self.image_path = image_path
        self.mask_path = mask_path
        self.train = train  # 'train' or 'test'
        self.transform = transform # PIL.Image -> tensor

        # train index 뽑아두기
        df = pd.read_csv(self.tsv_path, sep='\t')
        self.valid_indices = df[df['train'] == train].index.tolist()

        # mask처리 - sub마다 maskload(shape: (Z, Y, X))
        # sub = re.search(r"(sub-\d+)", self.fmri_path).group(1)
        # mask_file = os.path.join(self.mask_path, f"{sub}_nsdgeneral.nii.gz")
        # mask_data = nib.load(mask_file).get_fdata()
        # mask_bool = (mask_data == 1)  # mask에 해당하는 부분 true 
        # self.mask_tensor = torch.tensor(mask_bool).nonzero(as_tuple=True) # tensor로 변환 + 위치로 저장 -> 속도 빠름

    def __len__(self):
        return len(self.valid_indices)

    def __getitem__(self, idx): 
        actual_idx = self.valid_indices[idx]  # idx -> 기존 데이터에서의 진짜 인덱스

        # 해당 볼륨만 로드 (4D → 3D)
        # fmri = nib.load(self.fmri_path).dataobj
        # fmri_vol = torch.tensor(fmri[:, :, :, actual_idx]).float()

        # 마스크 적용: (Z, Y, X) → (N,)
        # fmri_vol = fmri_vol[self.mask_tensor]

        # npy 로딩
        fmri_all = np.load(self.fmri_path, mmap_mode='r', allow_pickle=True)  # shape: (T, N_voxels)
        fmri_vol = torch.tensor(fmri_all[actual_idx]).float()  # shape: (N_voxels,)

        # image column 한 행만 로딩
        row = pd.read_csv(self.tsv_path, sep='\t', skiprows=range(1, actual_idx + 1), nrows=1)
        image_id = row['image'].values[0]

        # 이미지 로딩
        image_path = os.path.join(self.image_path, image_id + '.jpg')
        image = Image.open(image_path).convert('RGB')
        if self.transform:
            image = self.transform(image)

        return fmri_vol, image

class TestDataset(Dataset): # sub단위로 실행
    def __init__(self, fmri_info_list, image_path, low_image_path, mask_path, transform, use_low_image):
        self.fmri_info_list = fmri_info_list  # 리스트: {'image_id': str, 'fmri_volumes': [(path1, idx1), (path2, idx2), (path3, idx3)]}
        self.image_path = image_path
        self.low_image_path = low_image_path
        self.mask_path = mask_path
        self.transform = transform # PIL.Image -> tensor
        self.use_low_image = use_low_image

        # mask처리 - sub마다 maskload(shape: (Z, Y, X))
        # sub = re.search(r"(sub-\d+)", self.fmri_info_list[0]['fmri_volumes'][0][0]).group(1)
        # mask_file = os.path.join(self.mask_path, f"{sub}_nsdgeneral.nii.gz")
        # mask_data = nib.load(mask_file).get_fdata()
        # mask_bool = (mask_data == 1)  # mask에 해당하는 부분 true 
        # self.mask_tensor = torch.tensor(mask_bool).nonzero(as_tuple=True) # tensor로 변환 + 위치로 저장 -> 속도 빠름

        
    def __len__(self):
        return len(self.fmri_info_list)

    def __getitem__(self, idx):
        info = self.fmri_info_list[idx]
        image_id = info['image_id']
        fmri_list = info['fmri_volumes']  # [(path1, idx1), (path2, idx2), (path3, idx3)]
        
        fmri_vols = []
        for path, i in fmri_list:
            data = np.load(path, mmap_mode='r', allow_pickle=True)  # shape: (T, N_voxels)
            fmri_vol = torch.tensor(data[i]).float()  # shape: (N_voxels,)
            fmri_vols.append(fmri_vol)


            # data = nib.load(path).dataobj
            # fmri_vol = torch.tensor(data[:, :, :, i]).float()
            # # 마스크 적용: (Z, Y, X) → (N,)
            # fmri_vol = fmri_vol[self.mask_tensor]  
            # fmri_vols.append(fmri_vol)

        # idx당 하나의 volume 생성
        fmri_avg = torch.stack(fmri_vols).mean(0)  # mean(0): voxel-wise 평균 -> 결과 shape(X, Y, Z)

        image_path = os.path.join(self.image_path, image_id + '.jpg')
        low_image_path = os.path.join(self.low_image_path, image_id + ".jpg")

        image = Image.open(image_path).convert('RGB')
        if self.transform:
            image = self.transform(image)
        
        
        if self.use_low_image:
            low_image = Image.open(low_image_path).convert('RGB')
            if self.transform:
                low_image = self.transform(low_image)
        else:
            low_image = []

        return fmri_avg, image, low_image, image_id
    
class hug_TrainDataset(Dataset): # ses단위로 실행
    def __init__(self, fmri_path, image_path, transform):
        self.data = np.load(fmri_path, mmap_mode='r', allow_pickle=True) # 포인터만 받아와서 메모리에 올라온 것은 아님
        self.fmri = self.data['X']
        self.cocoid = self.data['Y']
        self.image_path = image_path
        self.transform = transform # PIL.Image -> tensor
       

    def __len__(self):
        return len(self.cocoid)

    def __getitem__(self, idx): 
        # fMRI 데이터 로딩
        fmri_vol = torch.tensor(self.fmri[idx], dtype=torch.float32)

        # 이미지 로딩
        image_path = os.path.join(self.image_path, self.cocoid[idx])
        image = Image.open(image_path).convert('RGB')
        if self.transform:
            image = self.transform(image)

        return fmri_vol, image

class hug_TestDataset(Dataset): # ses단위로 실행
    def __init__(self, fmri_path, image_path, low_image_path, transform, use_low_image):
        self.data = np.load(fmri_path, mmap_mode='r', allow_pickle=True) # 포인터만 받아와서 메모리에 올라온 것은 아님
        self.fmri = self.data['X']
        self.cocoid = self.data['Y']
        self.image_path = image_path
        self.low_image_path = low_image_path
        self.transform = transform # PIL.Image -> tensor
        self.use_low_image = use_low_image

    def __len__(self):
        return len(self.cocoid)

    def __getitem__(self, idx): 
        # fMRI 데이터 로딩
        fmri_vol = torch.tensor(self.fmri[idx], dtype=torch.float32)

        # 이미지 로딩
        image_path = os.path.join(self.image_path, self.cocoid[idx])
        low_image_path = os.path.join(self.low_image_path, self.cocoid[idx])

        image = Image.open(image_path).convert('RGB')
        if self.transform:
            image = self.transform(image)

        if self.use_low_image:
            low_image = Image.open(low_image_path).convert('RGB')
            if self.transform:
                low_image = self.transform(low_image)
        else:
            low_image = []

        return fmri_vol, image, low_image, self.cocoid[idx]
    
class FuncSpatial_TrainDataset(Dataset): # ses단위로 실행
    def __init__(self, fmri_path, image_path, transform):
        self.data = np.load(fmri_path, mmap_mode='r', allow_pickle=True) # 포인터만 받아와서 메모리에 올라온 것은 아님
        self.fmri = self.data['X']
        self.cocoid = self.data['Y']
        self.image_path = image_path
        self.transform = transform # PIL.Image -> tensor
       

    def __len__(self):
        return len(self.cocoid)

    def __getitem__(self, idx): 
        # fMRI 데이터 로딩
        fmri_vol = torch.tensor(self.fmri[idx], dtype=torch.float32)

        # 이미지 로딩
        image_path = os.path.join(self.image_path, self.cocoid[idx])
        image = Image.open(image_path).convert('RGB')
        if self.transform:
            image = self.transform(image)

        return fmri_vol, image

class FuncSpatial_TestDataset(Dataset): # ses단위로 실행
    def __init__(self, fmri_path, image_path, low_image_path, transform, use_low_image):
        self.data = np.load(fmri_path, mmap_mode='r', allow_pickle=True) # 포인터만 받아와서 메모리에 올라온 것은 아님
        self.fmri = self.data['X']
        self.cocoid = self.data['Y']
        self.image_path = image_path
        self.low_image_path = low_image_path
        self.transform = transform # PIL.Image -> tensor
        self.use_low_image = use_low_image

    def __len__(self):
        return len(self.cocoid)

    def __getitem__(self, idx): 
        # fMRI 데이터 로딩
        fmri_vol = torch.tensor(self.fmri[idx], dtype=torch.float32)

        # 이미지 로딩
        image_path = os.path.join(self.image_path, self.cocoid[idx])
        low_image_path = os.path.join(self.low_image_path, self.cocoid[idx])

        image = Image.open(image_path).convert('RGB')
        if self.transform:
            image = self.transform(image)

        if self.use_low_image:
            low_image = Image.open(low_image_path).convert('RGB')
            if self.transform:
                low_image = self.transform(low_image)
        else:
            low_image = []

        return fmri_vol, image, low_image, self.cocoid[idx]

def sub1_train_dataset(args): # ses단위로 실행

    root_dir = args.root_dir
    fmri_dir = args.fmri_dir
    fmri_detail_dir = args.fmri_detail_dir
    image_dir = args.image_dir
    transform = transforms.ToTensor()
    
    # 세션 자동 추출
    # pattern = f"{root_dir}/{fmri_dir}/{fmri_detail_dir}/sub-01/ses-*/func/sub-01_ses-*_desc-betaroizscore.nii.gz"
    pattern = f"{root_dir}/{fmri_dir}/{fmri_detail_dir}/sub-01/ses-*/func/sub-01_ses-*_desc-betaroizscore.npy"
    fmri_files = glob.glob(pattern)
    sessions = sorted([re.search(r'ses-(\d+)', f).group(1) for f in fmri_files]) # ex) 01,02 ... 추출

    train_datasets = []

    for ses in sessions:
        # fmri_path = f"{root_dir}/{fmri_dir}/{fmri_detail_dir}/sub-01/ses-{ses}/func/sub-01_ses-{ses}_desc-betaroizscore.nii.gz"
        fmri_path = f"{root_dir}/{fmri_dir}/{fmri_detail_dir}/sub-01/ses-{ses}/func/sub-01_ses-{ses}_desc-betaroizscore.npy"
        tsv_path = f"{root_dir}/{fmri_dir}/{fmri_detail_dir}/sub-01/ses-{ses}/func/sub-01_ses-{ses}_task-image_events.tsv"
        image_path = f"{root_dir}/{image_dir}"
        mask_path = f"{root_dir}/{fmri_dir}/{fmri_detail_dir}/sub-01"
        
        train_datasets.append(TrainDataset(fmri_path, tsv_path, image_path, mask_path, transform, train=1))

    # Dataset 합침
    train_dataset = ConcatDataset(train_datasets)
    
    return train_dataset

def sub1_test_dataset(args): # sub단위로 실행

    root_dir = args.root_dir
    fmri_dir = args.fmri_dir
    fmri_detail_dir = args.fmri_detail_dir
    image_dir = args.image_dir
    code_dir = args.code_dir
    output_dir= args.output_dir
    transform = transforms.ToTensor()
    use_low_image = args.use_low_image

    # 모든 nii 경로 뽑음
    # pattern = f"{root_dir}/{fmri_dir}/{fmri_detail_dir}/sub-01/ses-*/func/sub-01_ses-*_desc-betaroizscore.nii.gz"
    pattern = f"{root_dir}/{fmri_dir}/{fmri_detail_dir}/sub-01/ses-*/func/sub-01_ses-*_desc-betaroizscore.npy"
    fmri_files = sorted(glob.glob(pattern))

    # 모든 trial 정리
    '''
    image_info = [
        {'image_id': 'img_001', 'fmri_path': 'ses-01.nii.gz', 'volume_idx': 4},
        {'image_id': 'img_001', 'fmri_path': 'ses-03.nii.gz', 'volume_idx': 12},
        {'image_id': 'img_001', 'fmri_path': 'ses-08.nii.gz', 'volume_idx': 7},
        {'image_id': 'img_002', 'fmri_path': 'ses-01.nii.gz', 'volume_idx': 9},
        {'image_id': 'img_002', 'fmri_path': 'ses-03.nii.gz', 'volume_idx': 14},
    ]
    '''
    image_info = []
    for fmri_path in fmri_files:
        # tsv_path = fmri_path.replace('_desc-betaroizscore.nii.gz', '_task-image_events.tsv')
        tsv_path = fmri_path.replace('_desc-betaroizscore.npy', '_task-image_events.tsv')
        df = pd.read_csv(tsv_path, sep='\t')
        test_df = df[df['train'] == 0].copy()

        for idx, row in test_df.iterrows():
            image_id = row['image']
            image_info.append({'image_id': image_id, 'fmri_path': fmri_path, 'volume_idx': idx})

    # image_info를 Dataframe으로 만들고 group처리
    image_df = pd.DataFrame(image_info)
    grouped = image_df.groupby('image_id')
    
    # 한 image에 해당하는 모든 fMRI idx정보 저장
    '''
    {
        'image_id': 'img_001',
        'fmri_volumes': [
            ('ses-01.nii.gz', 4),
            ('ses-03.nii.gz', 12),
            ('ses-08.nii.gz', 7)
        ]
    },
    '''
    averaged_list = []
    for image_id, group in grouped:
        fmri_volumes = [(row['fmri_path'], row['volume_idx']) for _, row in group.iterrows()]
        averaged_list.append({
            'image_id': image_id,
            'fmri_volumes': fmri_volumes
        })
    
    image_path = f"{root_dir}/{image_dir}"
    low_image_path = f"{root_dir}/{code_dir}/{output_dir}/low_recons"
    mask_path = f"{root_dir}/{fmri_dir}/{fmri_detail_dir}/sub-01"

    test_dataset = TestDataset(averaged_list, image_path, low_image_path, mask_path, transform, use_low_image)

    return test_dataset

def sub1_train_dataset_hug(args):
    root_dir = args.root_dir
    fmri_dir = args.fmri_dir
    fmri_detail_dir = args.fmri_detail_dir
    image_dir = args.image_dir
    transform = transforms.ToTensor()
    
    fmri_path = f"{root_dir}/{fmri_dir}/{fmri_detail_dir}/fmri_with_labels.npz"
    image_path = f"{root_dir}/{image_dir}"
 
    train_dataset = hug_TrainDataset(fmri_path, image_path, transform)
    
    return train_dataset

def sub1_test_dataset_hug(args):
    root_dir = args.root_dir
    fmri_dir = args.fmri_dir
    fmri_detail_dir = args.fmri_detail_dir
    image_dir = args.image_dir
    code_dir = args.code_dir
    output_dir= args.output_dir
    transform = transforms.ToTensor()
    use_low_image = args.use_low_image
    
    fmri_path = f"{root_dir}/{fmri_dir}/{fmri_detail_dir}/fmri_with_labels_test.npz"
    image_path = f"{root_dir}/{image_dir}"
    low_image_path = f"{root_dir}/{code_dir}/{output_dir}/low_recons"
 
    test_dataset = hug_TestDataset(fmri_path, image_path, low_image_path, transform, use_low_image)
    
    return test_dataset

def sub1_train_dataset_FuncSpatial(args):
    root_dir = args.root_dir
    fmri_dir = args.fmri_dir
    fmri_detail_dir = args.fmri_detail_dir
    image_dir = args.image_dir
    transform = transforms.ToTensor()
    
    fmri_path = f"{root_dir}/{fmri_dir}/{fmri_detail_dir}/beta_hf_dk_train.npz"
    image_path = f"{root_dir}/{image_dir}"
 
    train_dataset = FuncSpatial_TrainDataset(fmri_path, image_path, transform)
    
    return train_dataset

def sub1_test_dataset_FuncSpatial(args):
    root_dir = args.root_dir
    fmri_dir = args.fmri_dir
    fmri_detail_dir = args.fmri_detail_dir
    image_dir = args.image_dir
    code_dir = args.code_dir
    output_dir= args.output_dir
    transform = transforms.ToTensor()
    use_low_image = args.use_low_image
    
    fmri_path = f"{root_dir}/{fmri_dir}/{fmri_detail_dir}/beta_hf_dk_test.npz"
    image_path = f"{root_dir}/{image_dir}"
    low_image_path = f"{root_dir}/{code_dir}/{output_dir}/low_recons"
 
    test_dataset = FuncSpatial_TestDataset(fmri_path, image_path, low_image_path, transform, use_low_image)
    
    return test_dataset

def get_dataloader(args):

    if args.mode == 'train':
        train_dataset = sub1_train_dataset_FuncSpatial(args)
        train_loader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=args.num_workers, prefetch_factor=args.prefetch_factor, persistent_workers=False, pin_memory=True, shuffle=True, worker_init_fn=worker_init_fn)
        return train_loader
    
    if args.mode == 'inference':
        test_dataset = sub1_test_dataset_FuncSpatial(args)
        test_loader = DataLoader(test_dataset, batch_size=args.inference_batch_size, num_workers=args.num_workers, prefetch_factor=args.prefetch_factor, persistent_workers=False, pin_memory=True, worker_init_fn=worker_init_fn)
        return test_loader
    
def worker_init_fn(worker_id):
    seed = torch.initial_seed() % 2**32  # worker별 고유 seed 생성
    np.random.seed(seed)
    random.seed(seed)    

    